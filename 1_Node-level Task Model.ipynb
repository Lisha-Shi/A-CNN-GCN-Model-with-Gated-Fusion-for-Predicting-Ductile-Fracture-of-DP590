{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451263d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GCNConv, MessagePassing  # Import GCNConv\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "# 2. Model Definition\n",
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, cnn_dim):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 800), \n",
    "#             nn.Sigmoid()\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.mfrac_boost = nn.Parameter(torch.tensor(3.0))\n",
    "        self.spatial_groups = 25\n",
    "        self.channels_per_group = cnn_dim // self.spatial_groups\n",
    "\n",
    "    def forward(self, cnn_feat, mfrac):\n",
    "        # Generate gate weights from mfrac\n",
    "        gate_weights = self.gate(mfrac)\n",
    "        # Group weights for spatial attention\n",
    "        grouped_weights = gate_weights.view(-1, self.channels_per_group, self.spatial_groups)\n",
    "        spatial_weights = grouped_weights.mean(dim=1)\n",
    "        expanded_weights = spatial_weights.unsqueeze(1).repeat(1, self.channels_per_group, 1)\n",
    "        gate_weights = expanded_weights.reshape_as(gate_weights)\n",
    "        # Amplify gate weights\n",
    "        gate_weights = gate_weights * 2.0\n",
    "        # Boost mfrac value\n",
    "        boosted_mfrac = mfrac * self.mfrac_boost\n",
    "        # Concatenate gated features with boosted mfrac\n",
    "        return torch.cat([cnn_feat * gate_weights, boosted_mfrac], dim=1), gate_weights\n",
    "\n",
    "class Optimized_CNN_GCN(nn.Module):\n",
    "    def __init__(self, input_dim=(21, 21), filters=32, kernel_size=3, \n",
    "                 dense_units=64, dropout_rate=0, gcn_hidden_dim=64, \n",
    "                 learning_rate=0.001):\n",
    "        super(Optimized_CNN_GCN, self).__init__()\n",
    "        # CNN layers for feature extraction\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Calculate CNN output dimension dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 1, *input_dim)\n",
    "            dummy_output = self.cnn(dummy_input)\n",
    "            self.cnn_output_dim = dummy_output.view(-1).shape[0]\n",
    "        \n",
    "        # Gated fusion module\n",
    "        self.fusion = GatedFusion(self.cnn_output_dim)\n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(self.cnn_output_dim + 1, gcn_hidden_dim)\n",
    "        self.conv2 = GCNConv(gcn_hidden_dim, gcn_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(gcn_hidden_dim, 1)\n",
    "#         self.sigmoid = nn.Sigmoid() # Add Sigmoid activation\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Add attributes for visualization\n",
    "        self.gate_weights = None\n",
    "        self.attn_weights = None\n",
    "        self.conv1_attention = torch.randn(4, 1)  # Random data for visualization\n",
    "        self.conv2_attention = torch.randn(4, 1)  # Random data for visualization\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x_all = data.x\n",
    "        num_nodes = data.num_nodes\n",
    "        \n",
    "        # Split input into CNN features and mfrac\n",
    "        x_cnn = x_all[:, :-1].view(num_nodes, 1, 21, 21)\n",
    "        x_mfrac = x_all[:, -1].unsqueeze(1)\n",
    "        \n",
    "        # Process with CNN\n",
    "        x_cnn = self.cnn(x_cnn)\n",
    "        x_cnn = x_cnn.view(num_nodes, -1)\n",
    "        \n",
    "        # Apply gated fusion\n",
    "        x, gate_weights = self.fusion(x_cnn, x_mfrac)\n",
    "        self.gate_weights = gate_weights\n",
    "        self.attn_weights = torch.randn(num_nodes, 1)  # Random data for visualization\n",
    "        \n",
    "        # Apply GCN layers\n",
    "        edge_index = data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.linear(x)\n",
    "#         x = self.sigmoid(x)  # Apply Sigmoid\n",
    "        return x\n",
    "    \n",
    "# Instant model test\n",
    "sample_data = graphs[0]  # Test with first sample\n",
    "model = Optimized_CNN_GCN()\n",
    "output = model(sample_data)\n",
    "print(\"\\nModel test output:\")\n",
    "print(output.shape)\n",
    "print(output)\n",
    "\n",
    "# Check model structure\n",
    "print(\"\\nModel structure:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(45)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "np.random.seed(45)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Prepare data loaders\n",
    "np.random.shuffle(graphs)\n",
    "train_dataset = graphs[:int(0.7*len(graphs))]\n",
    "test_dataset = graphs[int(0.7*len(graphs)):]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Optimized_CNN_GCN(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    dense_units=128,\n",
    "    dropout_rate=0.2,\n",
    "    gcn_hidden_dim=32,\n",
    "    learning_rate=0.0015\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training parameters\n",
    "epochs = 200\n",
    "patience = 30\n",
    "min_delta = 0.00001\n",
    "\n",
    "# Training records\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_r2_scores = []\n",
    "test_r2_scores = []\n",
    "best_test_loss = float('inf')\n",
    "best_model_state = None\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.num_graphs\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            test_loss += loss.item() * data.num_graphs\n",
    "            test_preds.append(out.cpu().numpy())\n",
    "            test_targets.append(data.y.cpu().numpy())\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Calculate R² score\n",
    "    test_preds = np.concatenate(test_preds, axis=0)\n",
    "    test_targets = np.concatenate(test_targets, axis=0)\n",
    "    test_r2 = r2_score(test_targets, test_preds)\n",
    "    test_r2_scores.append(test_r2)\n",
    "    \n",
    "    # Training set evaluation\n",
    "    model.eval()\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            train_preds.append(out.cpu().numpy())\n",
    "            train_targets.append(data.y.cpu().numpy())\n",
    "    train_preds = np.concatenate(train_preds, axis=0)\n",
    "    train_targets = np.concatenate(train_targets, axis=0)\n",
    "    train_r2 = r2_score(train_targets, train_preds)\n",
    "    train_r2_scores.append(train_r2)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if test_loss < best_test_loss - min_delta:\n",
    "        best_test_loss = test_loss\n",
    "        best_model_state = deepcopy(model.state_dict())\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}: '\n",
    "              f'Train Loss: {train_loss:.5f}, Test Loss: {test_loss:.5f}, '\n",
    "              f'Train R2: {train_r2:.5f}, Test R2: {test_r2:.5f}')\n",
    "    \n",
    "    # Save model when early stopping is triggered\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch + 1}')\n",
    "        torch.save(best_model_state, 'best_model.pth')\n",
    "        print(\"Best model saved as best_model.pth\")\n",
    "        break\n",
    "\n",
    "# Save model when training completes normally\n",
    "if early_stop_counter < patience:\n",
    "    torch.save(best_model_state, 'best_model.pth')\n",
    "    print(\"Training completed, best model saved as best_model.pth\")\n",
    "\n",
    "# Load best model for testing evaluation\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "# Test set evaluation\n",
    "test_loss = 0\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        test_loss += loss.item() * data.num_graphs\n",
    "        test_preds.append(out.cpu().numpy())\n",
    "        test_targets.append(data.y.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_targets = np.concatenate(test_targets, axis=0)\n",
    "test_r2 = r2_score(test_targets, test_preds)\n",
    "\n",
    "# Calculate training set metrics\n",
    "train_preds = []\n",
    "train_targets = []\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        train_preds.append(out.cpu().numpy())\n",
    "        train_targets.append(data.y.cpu().numpy())\n",
    "train_preds = np.concatenate(train_preds, axis=0)\n",
    "train_targets = np.concatenate(train_targets, axis=0)\n",
    "\n",
    "# Define function to calculate metrics\n",
    "def calculate_metrics(targets, preds):\n",
    "    mse = np.mean((targets - preds) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(targets - preds))\n",
    "    r2 = r2_score(targets, preds)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Calculate metrics for each set\n",
    "train_rmse, train_mae, train_r2 = calculate_metrics(train_targets, train_preds)\n",
    "test_rmse, test_mae, test_r2 = calculate_metrics(test_targets, test_preds)\n",
    "\n",
    "# Print results\n",
    "print('\\n=== Final Results ===')\n",
    "print('Training Set - RMSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}'.format(train_rmse, train_mae, train_r2))\n",
    "print('Test Set - RMSE: {:.4f}, MAE: {:.4f}, R²: {:.4f}'.format(test_rmse, test_mae, test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167f082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
