{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef89180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Curves\n",
    "# Training curve visualization (modified to RMSE)\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 20,\n",
    "    'axes.labelsize': 22,\n",
    "    'xtick.labelsize': 24,\n",
    "    'ytick.labelsize': 24,\n",
    "    'legend.fontsize': 20,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.5\n",
    "})\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "# Modification: Convert MSE to RMSE\n",
    "train_rmse = [np.sqrt(x) for x in train_losses]\n",
    "test_rmse = [np.sqrt(x) for x in test_losses]  # Modified to test_rmse\n",
    "ax1.plot(train_rmse, label='Train RMSE', linewidth=2, color='blue')\n",
    "ax1.plot(test_rmse, label='Test RMSE', linewidth=2, color='red')  # Modified to test_rmse\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('RMSE Loss')  # Modified ylabel\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(train_r2_scores, label='Train R2', linewidth=2, color='blue')\n",
    "ax2.plot(test_r2_scores, label='Test R2', linewidth=2, color='red')  # Modified to test_r2\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('R2 Score')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prediction Results Scatter Plot (unchanged)\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['r', 'g', 'b', 'c', 'm']\n",
    "markers = ['o', 's', 'D', '^', 'v']\n",
    "labels = [f'{i}' for i in range(5)]\n",
    "node_metrics = []\n",
    "\n",
    "# for node_id in range(5):\n",
    "#     mask = test_node_ids == node_id\n",
    "#     t = test_targets[mask]\n",
    "#     p = test_preds[mask]\n",
    "\n",
    "#     plt.scatter(t, p, \n",
    "#                c=colors[node_id], \n",
    "#                marker=markers[node_id],\n",
    "#                s=90,\n",
    "#                alpha=0.8,\n",
    "#                label=labels[node_id])\n",
    "\n",
    "#     # Modification: Add RMSE calculation\n",
    "#     mse = np.mean((t - p) ** 2)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     r2 = r2_score(t, p)\n",
    "#     node_metrics.append({\n",
    "#         'node_id': node_id,\n",
    "#         'mse': mse,\n",
    "#         'rmse': rmse,  # Added RMSE\n",
    "#         'r2': r2,\n",
    "#         'count': len(t)\n",
    "#     })\n",
    "\n",
    "# min_val = 0\n",
    "# max_val = 0.5\n",
    "# plt.plot([min_val, max_val], [min_val, max_val], 'k-', linewidth=1.5, alpha=0.7)\n",
    "# plt.xlim(-0.02, 0.5)\n",
    "# plt.ylim(-0.02, 0.5)\n",
    "# plt.xticks(np.arange(0, 0.51, 0.1))\n",
    "# plt.yticks(np.arange(0, 0.51, 0.1))\n",
    "# plt.xlabel('True Values', fontsize=20, weight='normal')\n",
    "# plt.ylabel('Predictions', fontsize=20, weight='normal')\n",
    "# plt.grid(True, linestyle='--', alpha=0.3)\n",
    "# legend = plt.legend(title='NodeNum', fontsize=18)\n",
    "# plt.setp(legend.get_title(), fontsize=16)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Node Performance Evaluation (add RMSE output)\n",
    "# print(\"\\n=== Node Prediction Performance Evaluation ===\")\n",
    "# print(f\"{'Node':<6}{'Samples':<8}{'MSE':<12}{'RMSE':<12}{'R2':<10}\")\n",
    "# print(\"-\" * 50)\n",
    "# sorted_by_mse = sorted(node_metrics, key=lambda x: x['mse'])\n",
    "# for metrics in sorted_by_mse:\n",
    "#     print(f\"{metrics['node_id']:<6}{metrics['count']:<8}{metrics['mse']:.6f}{metrics['rmse']:.6f}{metrics['r2']:.4f}\")\n",
    "\n",
    "# print(\"\\nSorted by R2:\")\n",
    "# sorted_by_r2 = sorted(node_metrics, key=lambda x: -x['r2'])\n",
    "# for metrics in sorted_by_r2:\n",
    "#     print(f\"Node{metrics['node_id']}: R2={metrics['r2']:.4f}, RMSE={metrics['rmse']:.4f}, MSE={metrics['mse']:.6f}\")\n",
    "\n",
    "# Gating Response Visualization (unchanged)\n",
    "model.eval()\n",
    "test_values = torch.linspace(0, 0.26, 100).unsqueeze(1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    raw_weights = model.fusion.gate(test_values)\n",
    "    grouped_weights = raw_weights.view(100, 32, 25).mean(dim=1)\n",
    "    expanded_weights = grouped_weights.unsqueeze(1).repeat(1, 32, 1).view(100, 800)\n",
    "    mean_raw_weights = raw_weights.mean(dim=1)\n",
    "    mean_grouped_weights = grouped_weights.mean(dim=1)\n",
    "    heatmap_data = grouped_weights.mean(dim=0).view(5, 5).cpu()\n",
    "    mean_spatial_weights = heatmap_data.mean()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Plot raw weights\n",
    "for i in range(800):\n",
    "    plt.plot(test_values.cpu(), raw_weights[:, i].cpu(), \n",
    "            color='blue', alpha=0.15, linewidth=0.5, \n",
    "            label='Raw Weights' if i == 0 else \"\")\n",
    "\n",
    "# Plot grouped weights\n",
    "for i in range(0, 800, 32):\n",
    "    plt.plot(test_values.cpu(), expanded_weights[:, i].cpu(),\n",
    "            color='red', linewidth=1.5,\n",
    "            label='Grouped Weights' if i == 0 else \"\")\n",
    "\n",
    "# Plot mean values\n",
    "plt.plot(test_values.cpu(), mean_raw_weights.cpu(), \n",
    "        color='black', linewidth=3, linestyle='--', \n",
    "        label='Mean Raw Weights')\n",
    "plt.plot(test_values.cpu(), mean_grouped_weights.cpu(),\n",
    "        color='green', linewidth=3, linestyle='-.', \n",
    "        label='Mean Grouped Weights')\n",
    "\n",
    "plt.xlabel(\"Global Martensite Fraction Value\", fontsize=22)\n",
    "plt.ylabel(\"Gate Weight Value\", fontsize=22)\n",
    "plt.grid(True, alpha=0.3)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), \n",
    "          fontsize=18, framealpha=0.5)\n",
    "plt.tick_params(axis='both', which='major', labelsize=22)\n",
    "\n",
    "# Heatmap subplot\n",
    "plt.subplot(2, 1, 2)\n",
    "im = plt.imshow(heatmap_data, cmap='viridis', aspect=1)\n",
    "plt.title(f\"Spatial Weight Distribution (Mean={mean_spatial_weights:.3f})\", \n",
    "          fontsize=22, pad=20)\n",
    "cbar = plt.colorbar(im, label='Weight Value', shrink=0.8)\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "cbar.set_label('Weight Value', fontsize=16)\n",
    "plt.xticks(np.arange(5), labels=np.arange(5), fontsize=18)\n",
    "plt.yticks(np.arange(5), labels=np.arange(5), fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prediction Results Scatter Plot (including training/test sets)\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Define dataset styles\n",
    "dataset_styles = {\n",
    "    'train': {'color': 'indigo', 'marker': 'o', 'label': 'TrainSet', 'alpha': 1, 's': 120},\n",
    "    'test': {'color': 'deeppink', 'marker': 'D', 'label': 'TestSet', 'alpha': 0.8, 's': 140}\n",
    "}\n",
    "\n",
    "# Collect prediction results for training and test sets\n",
    "all_datasets = {\n",
    "    'train': {'loader': train_loader, 'true': [], 'pred': []},\n",
    "    'test': {'loader': test_loader, 'true': [], 'pred': []}\n",
    "}\n",
    "\n",
    "# Get all prediction results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for dataset_name in all_datasets:\n",
    "        loader = all_datasets[dataset_name]['loader']\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            all_datasets[dataset_name]['true'].append(data.y.cpu().numpy())\n",
    "            all_datasets[dataset_name]['pred'].append(out.cpu().numpy())\n",
    "\n",
    "# Plot scatter plot (distinguished by dataset)\n",
    "for dataset_name in ['train', 'test']:\n",
    "    true_values = np.concatenate(all_datasets[dataset_name]['true'])\n",
    "    pred_values = np.concatenate(all_datasets[dataset_name]['pred'])\n",
    "    style = dataset_styles[dataset_name]\n",
    "    plt.scatter(\n",
    "        true_values, pred_values,\n",
    "        c=style['color'],\n",
    "        marker=style['marker'],\n",
    "        s=style['s'],\n",
    "        alpha=style['alpha'],\n",
    "        label=style['label']\n",
    "    )\n",
    "\n",
    "# Plot ideal reference line\n",
    "min_val = -0.04\n",
    "max_val = 0.5\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Chart decoration\n",
    "plt.xlim(-0.04, 0.5)\n",
    "plt.ylim(-0.04, 0.5)\n",
    "plt.xlabel('True Values', fontsize=22)\n",
    "plt.ylabel('Predictions', fontsize=22)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Set legend text size\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
